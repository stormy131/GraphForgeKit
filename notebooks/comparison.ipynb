{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b2fa434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import ReLU, Linear\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
    "from torch import from_numpy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b576cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Boilerplate setup for Jupyter imports\n",
    "\n",
    "root = Path(os.getcwd()).parent\n",
    "sys.path.append(\n",
    "    (root / \"src\").as_posix()\n",
    ")\n",
    "\n",
    "import configs as config_module\n",
    "import enhancer as enhancer_module\n",
    "import strategies as encoders_module\n",
    "import schema.edges as edges_module\n",
    "import schema.network as network_module\n",
    "import schema.data as data_module\n",
    "import utils.metrics as utils_module\n",
    "\n",
    "reload(edges_module)\n",
    "reload(config_module)\n",
    "reload(enhancer_module)\n",
    "reload(encoders_module)\n",
    "reload(network_module)\n",
    "reload(data_module)\n",
    "reload(utils_module)\n",
    "\n",
    "PathConfig, TrainConfig = config_module.PathConfig, config_module.TrainConfig\n",
    "Enhancer = enhancer_module.Enhancer\n",
    "get_default_encoders = encoders_module.get_default_encoders\n",
    "NetworkConfig, EnhancerData = network_module.NetworkConfig, data_module.EnhancerData\n",
    "GraphSetup = edges_module.GraphSetup\n",
    "euclid_metric, haversine_metric = utils_module.euclid_dist, utils_module.haversine_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9649f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config = PathConfig(data_root=\"../data\")\n",
    "path_config.target_data = path_config.data_root / \"processed/np/Melbourne_housing_FULL.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "304606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_config.target_data, \"rb\") as f:\n",
    "    unpacked = np.load(f)\n",
    "    data, target, spatial = unpacked[\"data\"], unpacked[\"target\"], unpacked[\"spatial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68d0c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "spatial_processed = scaler.fit_transform(spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fbcc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target, train_spatial, test_spatial, train_spatial_pcs, test_spatial_pcs = (\n",
    "    train_test_split(data, target, spatial, spatial_processed, test_size=0.2)\n",
    ")\n",
    "\n",
    "train_data, val_data, train_target, val_target, train_spatial, val_spatial, train_spatial_pcs, val_spatial_pcs = (\n",
    "    train_test_split(train_data, train_target, train_spatial, train_spatial_pcs, test_size=0.125)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6999532880053978 0.2000311413297348 0.1000155706648674\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    train_data.shape[0] / data.shape[0],\n",
    "    test_data.shape[0] / data.shape[0],\n",
    "    val_data.shape[0] / data.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613a0fd",
   "metadata": {},
   "source": [
    "## Fixed network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c3e3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = [128, 128, 64]\n",
    "ACTIVATION_T = ReLU\n",
    "\n",
    "LOSS = torch.nn.MSELoss()\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d25346",
   "metadata": {},
   "source": [
    "## Classical DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5710f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (\n",
    "    torch.from_numpy(\n",
    "        np.hstack((train_data, train_spatial_pcs)).astype(np.float32)\n",
    "    ),\n",
    "    torch.from_numpy(train_target.astype(np.float32)),\n",
    ")\n",
    "\n",
    "X_test, y_test = (\n",
    "    torch.from_numpy(\n",
    "        np.hstack((test_data, test_spatial_pcs)).astype(np.float32)\n",
    "    ),\n",
    "    torch.from_numpy(test_target.astype(np.float32)),\n",
    ")\n",
    "\n",
    "X_val, y_val = (\n",
    "    torch.from_numpy(\n",
    "        np.hstack((val_data, val_spatial_pcs)).astype(np.float32)\n",
    "    ),\n",
    "    torch.from_numpy(val_target.astype(np.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "074704c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        tmp = [input_dim, *HIDDEN, output_dim]\n",
    "\n",
    "        for layer_in, layer_out in zip(tmp, tmp[1:]):\n",
    "            layers.append(Linear(layer_in, layer_out))\n",
    "            layers.append(ACTIVATION_T())\n",
    "\n",
    "        self.hidden = torch.nn.Sequential(*layers[:-1])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.hidden(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fe18e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "model = Model(X_train.shape[1], 1)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba61825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation loss = 1.356E+12\n",
      "Epoch 1: Validation loss = 1.356E+12\n",
      "Epoch 2: Validation loss = 1.356E+12\n",
      "Epoch 3: Validation loss = 1.355E+12\n",
      "Epoch 4: Validation loss = 1.355E+12\n",
      "Epoch 5: Validation loss = 1.354E+12\n",
      "Epoch 6: Validation loss = 1.353E+12\n",
      "Epoch 7: Validation loss = 1.351E+12\n",
      "Epoch 8: Validation loss = 1.348E+12\n",
      "Epoch 9: Validation loss = 1.344E+12\n",
      "Epoch 10: Validation loss = 1.338E+12\n",
      "Epoch 11: Validation loss = 1.332E+12\n",
      "Epoch 12: Validation loss = 1.324E+12\n",
      "Epoch 13: Validation loss = 1.314E+12\n",
      "Epoch 14: Validation loss = 1.302E+12\n",
      "Epoch 15: Validation loss = 1.288E+12\n",
      "Epoch 16: Validation loss = 1.273E+12\n",
      "Epoch 17: Validation loss = 1.255E+12\n",
      "Epoch 18: Validation loss = 1.234E+12\n",
      "Epoch 19: Validation loss = 1.212E+12\n",
      "Epoch 20: Validation loss = 1.187E+12\n",
      "Epoch 21: Validation loss = 1.160E+12\n",
      "Epoch 22: Validation loss = 1.130E+12\n",
      "Epoch 23: Validation loss = 1.099E+12\n",
      "Epoch 24: Validation loss = 1.065E+12\n",
      "Epoch 25: Validation loss = 1.029E+12\n",
      "Epoch 26: Validation loss = 9.911E+11\n",
      "Epoch 27: Validation loss = 9.516E+11\n",
      "Epoch 28: Validation loss = 9.107E+11\n",
      "Epoch 29: Validation loss = 8.685E+11\n",
      "Epoch 30: Validation loss = 8.254E+11\n",
      "Epoch 31: Validation loss = 7.816E+11\n",
      "Epoch 32: Validation loss = 7.375E+11\n",
      "Epoch 33: Validation loss = 6.934E+11\n",
      "Epoch 34: Validation loss = 6.496E+11\n",
      "Epoch 35: Validation loss = 6.064E+11\n",
      "Epoch 36: Validation loss = 5.643E+11\n",
      "Epoch 37: Validation loss = 5.235E+11\n",
      "Epoch 38: Validation loss = 4.844E+11\n",
      "Epoch 39: Validation loss = 4.472E+11\n",
      "Epoch 40: Validation loss = 4.122E+11\n",
      "Epoch 41: Validation loss = 3.795E+11\n",
      "Epoch 42: Validation loss = 3.494E+11\n",
      "Epoch 43: Validation loss = 3.219E+11\n",
      "Epoch 44: Validation loss = 2.970E+11\n",
      "Epoch 45: Validation loss = 2.748E+11\n",
      "Epoch 46: Validation loss = 2.551E+11\n",
      "Epoch 47: Validation loss = 2.378E+11\n",
      "Epoch 48: Validation loss = 2.227E+11\n",
      "Epoch 49: Validation loss = 2.097E+11\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    model.train()\n",
    "    for b_data, b_target in train_loader:\n",
    "        optim.zero_grad()\n",
    "        output = model(b_data)\n",
    "\n",
    "        loss = LOSS(output.squeeze(), b_target.squeeze())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_val)\n",
    "        val_loss = mean_squared_error(y_val.squeeze(), output.squeeze())\n",
    "        print(f\"Epoch {e}: Validation loss = {val_loss:.3E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0608f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL: MSE = 2.043E+11\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output = model(X_test)\n",
    "    mse = mean_squared_error(y_test.squeeze(), test_output.squeeze())\n",
    "    print(f\"FINAL: MSE = {mse:.3E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa387d9d",
   "metadata": {},
   "source": [
    "## Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "903ea0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer_data = EnhancerData(\n",
    "    from_numpy(data     .astype(np.float32)),\n",
    "    from_numpy(target   .astype(np.float32)),\n",
    "    from_numpy(spatial  .astype(np.float32)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0485b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(\n",
    "    n_epochs=EPOCHS,\n",
    "    learn_rate=LR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    loss_criteria=LOSS,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47dcc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder=[\n",
    "    SAGEConv(enhancer_data.features.shape[1], 64),\n",
    "    SAGEConv(64, 64),\n",
    "]\n",
    "\n",
    "estimator = []\n",
    "tmp = [64, *HIDDEN, 1]\n",
    "for layer_in, layer_out in zip(tmp, tmp[1:]):\n",
    "    estimator.append(Linear(layer_in, layer_out))\n",
    "    estimator.append(ACTIVATION_T())\n",
    "\n",
    "gnn_setup = NetworkConfig(\n",
    "    encoder, estimator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6917996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_strategy = encoders_module.KNNStrategy(\n",
    "    K=5,\n",
    "    dist_metric=euclid_metric,\n",
    "    cache_dir=path_config.edge_cache,\n",
    "    cache_id=\"melbourne_knn_5\",\n",
    ")\n",
    "\n",
    "threshold_strategy = encoders_module.ThresholdStrategy(\n",
    "    dist_metric=haversine_metric,\n",
    "    max_dist=3,\n",
    "    cache_dir=path_config.edge_cache,\n",
    "    cache_id=\"melbourne_threshold_3\",\n",
    ")\n",
    "\n",
    "anchor_strategy = encoders_module.AnchorStrategy(\n",
    "    n_repr=100,\n",
    "    cluster_sample_rate=0.03,\n",
    "    cache_dir=path_config.edge_cache,\n",
    "    cache_id=\"melbourne_anchors_100\",\n",
    ")\n",
    "\n",
    "grid_strategy = encoders_module.GridStrategy(\n",
    "    intra_edge_ratio=0.01,\n",
    "    source_inter_ratio=0.01,\n",
    "    k_connectivity=2,\n",
    "    bins=4,\n",
    "    cache_dir=path_config.edge_cache,\n",
    "    cache_id=\"melbourne_grid\",\n",
    ")\n",
    "\n",
    "input_strategies = [\n",
    "    GraphSetup(knn_strategy, enhancer_data),\n",
    "    GraphSetup(threshold_strategy, enhancer_data),\n",
    "    GraphSetup(anchor_strategy, enhancer_data),\n",
    "    GraphSetup(grid_strategy, enhancer_data),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eae0255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GNN training:   6%|▌         | 3/50 [00:01<00:28,  1.63epoch/s, val_loss=1.3e+12] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mEnhancer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompare_strategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgnn_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_strategies\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/afs/ms.mff.cuni.cz/u/k/kopyla/kopyl2024/src/enhancer.py:48\u001b[39m, in \u001b[36mEnhancer.compare_strategies\u001b[39m\u001b[34m(cls, gnn_config, train_config, strategies)\u001b[39m\n\u001b[32m     45\u001b[39m generated_edges = graph.edge_index\n\u001b[32m     46\u001b[39m test_graph = graph.subgraph(graph.test_mask)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m gnn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m output = gnn.predict(test_graph.x, test_graph.edge_index).numpy()\n\u001b[32m     50\u001b[39m runs.append( (strategy.slug, test_graph.y, output, generated_edges) )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/afs/ms.mff.cuni.cz/u/k/kopyla/kopyl2024/src/enhancer.py:62\u001b[39m, in \u001b[36mEnhancer.fit\u001b[39m\u001b[34m(self, data, verbose)\u001b[39m\n\u001b[32m     58\u001b[39m train_subgraph = graph_data.subgraph(graph_data.train_mask)\n\u001b[32m     59\u001b[39m val_subgraph = graph_data.subgraph(graph_data.val_mask)\n\u001b[32m     61\u001b[39m \u001b[38;5;28mself\u001b[39m._encoder = (\u001b[43mgnn\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_subgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_subgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     .encoder\n\u001b[32m     64\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gnn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/afs/ms.mff.cuni.cz/u/k/kopyla/kopyl2024/src/gnn/_gnn.py:63\u001b[39m, in \u001b[36mGNN.train\u001b[39m\u001b[34m(self, train_data, val_data, verbose)\u001b[39m\n\u001b[32m     60\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m._train_config.loss_criteria(out, y)\n\u001b[32m     62\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m val_predicts = \u001b[38;5;28mself\u001b[39m.predict(val_data.x, val_data.edge_index).squeeze()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    482\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    483\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    484\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    211\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    213\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    214\u001b[39m         group,\n\u001b[32m    215\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         state_steps,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/adam.py:784\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    782\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kopyl2024/venv/lib/python3.12/site-packages/torch/optim/adam.py:432\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    430\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "result = Enhancer.compare_strategies(gnn_setup, train_config, input_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5653934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option                   mean_squared_error      density    average degree    n connected components    largest component\n",
      "---------------------  --------------------  -----------  ----------------  ------------------------  -------------------\n",
      "melbourne_knn_5                 1.9681e+11   0.000322345           6.21031                        25                17602\n",
      "melbourne_threshold_3           9.40949e+10  0.0317267           611.056                           5                19020\n",
      "melbourne_anchors_100           1.17623e+11  0.000782952          15.0616                        102                  451\n",
      "melbourne_grid                  1.08393e+11  0.00414286           79.7003                          6                19224\n"
     ]
    }
   ],
   "source": [
    "print(result.get_comparison([mean_squared_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91a042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
